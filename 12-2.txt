자료구조 12주차 이론-2

지난시간

딕셔너리 adt
key와 element를 저장하는 자료구조.
key를 이용하여 탐색 삽입 삭제를 할 수 있다.
단 그 내부의 데이터들이 정렬되있을지, 정렬되어있지않을지는 상관없음.
즉 순서조건은 없는것.
물론 정렬된 형태의 배열로 구현하면 정렬되있겠다. -> 이것니 search table(or lookup table)  -> 이진탐색을 생각할 수 있어야한다.
그냥 들어온 순서대로 갖다가 붙인다.(정렬x) -> list-based dictionary (log file)

정렬되어있는 lookup table같은경우는 binary search를 이용하므로 탐색은 O(log n), 삽입삭제는 O(n) -> 삽입삭제가 적고 탐색이 잦은 곳에 이용

BST는 딕셔너리를 구현하는 방법 중하나.
이때 탐색,삽입,삭제 연산 수행시간이 O(h) (O(n))
balanced가 되면 모든 수행시간이 -> O(log n)

array를 이용해서 만들어보자. 그중에서 hashing이라는 기법을 이용하여.
sorting은 되어있지않지만, 어떠한 규칙에 의해서 만들어진다.

두가지 구성요소가 있다(hash function, array)

hash fucntion -> 하는일 : key를 배열의 index로 변환해주는 것
해시함수 두단계
1) hash cod : key를 int로 변환
2) compression function : int를 [0, N-1] 범위로 컴프레션.
-> 이 2개의 합성함수이다.
좋은 해시함수가 되기 위해선 잘 분산시켜야한다.

충돌(Collision)
: 서로 다른 해쉬의 값이 동일할때 충돌이 일어난다고 한다.

이러한 충돌을 해결하는 방법에 따라 해싱기법의 이름이 달라진다.

separate chaining: 같은 해쉬밸류를 가지는 애들을 linked list로 만들고, 그 시작지점을 인덱스안에 넣어준다.
배열외의 추가적인 메모리가 필요하다는 것이 특징

linear probing
open addressing 기법(개방주소법) : 해쉬밸류값이 같다하더라도, table에 어딘가에 저장하는 방법. (테이블 밖에다가 링크드 리스트 형태로하는게 아니라) -> 즉 모든 원소들을 테이블 안에 있게 만드는 것
그 방법 중 하나가 linear probing.
충돌이 생기면, 바로 다음 빈칸을 찾아서 저장히시키는 것. 물론 cicularly하게 돈다(환형).
이렇게 빈칸인지 아닌지 탐색하는걸 probe라고함. (충돌과는 조금 다르다. 충돌은 해쉬밸류가 같은 경우를 뜻하고, 빈칸을 찾아다닐 때는 꼭 그런건만은 아니기 때문)
이렇게 하다보면 충돌이 잦을수록 데이터가 점점 뭉치게된다. -> probe횟수가 늘어나기 때문에 점점 효율이 안좋아진다.

------------------------------------------------------------------------------

p.14

find(42)를 해봐라
-> 42 mod 13 = 3
해쉬밸류값이 3이므로, 3번 인덱스가보니까 빈칸.. -> 답은 빈칸? 아니면 다른 어딘가에 있을것이다? -> 당연히 42는 다른 칸에도 없다.?
erase(32) ?
-> 32 mod 13 = 6
prob 1 : 6번셀 -> 아님
prob 2 : 7번셀 -> 아님
porb 3 : 8번셀 -> 찾았다. 삭제

erase(31) ?
-> 31 mod 13 = 5
prob 1 : 5번셀 -> 아님
prob 2 : 6번셀 -> 아님
prob 3 : 7번셀 -> 아님
prob 4 : 8번셀 -> 빈칸   -> 뭐야 그럼 없는거?
==> 8번셀은 빈칸이긴하지만, 탐색시에 뒤칸들에게 영향을 줄 수 있으므로, 탐색할 때 그냥 지나가라~ 라고 하는 포스트잇을 자리에 붙여주자. but 삽입은 할 수는 있는 것.  => 이 작업을 삭제연산시에 해줘야한다.

p.15
find 연산 알고리즘

p.16
따라서 위에 포스트잇 같은 스페셜한 element를 넣어줘야한다. 이것을 available이라고 한다.
erase 연산 시, available이라는 스페셜 아이템을 거기다 넣어준다.
삽입연산시 available을 만나면 삽입을 해도되고
탐색연산시 available을 만나면 지나가면 된다.

p.17
double hashing. 이중 해싱.
hash function을 하나 더 주는것.
즉 충돌이 발생할경우, 두번째 해시함수를 이용해서 그 데이터를 찾을 또는 삽입할 자리를 결정한다.
(i + jd(k)) mod N  ?
두번째 해시값인 d(k)인 0이 되면 안된다. (이렇게되면 충돌시 의미가없으므로)
일차해쉬fucntion은 당연히 0을 가질 수 도있다. 인덱스가 0부터 N-1까지니까

그럼 이차해쉬값은 어떻게 만들거냐
d2(k) = q - (k mod q)
이때 q는 N(테이블사이즈)보다 찾은 소수.
k mod q를 하게되면, 값은 0~ q-1 사이가 될텐데, 이때 0값이 문제가 될 수있으므로, q - (k mod q)를 하면 범위가 1 ~ q로 바꿀 수 있다.

p.18
배열크기는 13
1차해쉬함수를 k mod 13으로 디자인,
2차해쉬함수를 7 - (k mod 7) 으로 디자인.

이때 8개의 데이터를 차례대로 삽입해보자.

4번째로 44를 삽입할 때, 1차해쉬값인 5 자리에 이미 데이터가 있으므로, 2차 해쉬값 만큼 인덱스를 + 시켜준다. (만약 그 자리에 또 있다? 그러면 또 그만큼 + 해준다.) -> probe 2회

7번째로 31를 삽입할때도 마찬가지. 1차 해쉬값자리에 이미 데이터가 있으므로 2차 해쉬값만큼 + 시켜준다. 또 그자리에 다른 값이 있으므로 다시 2차 해쉬값만큼 +. -> probe 3회

총 probe 횟수 11회.

p.19
해싱의 퍼포먼스.
워낙 빠르다.

worst case. 정말 운이 안좋으면 셀을 다 뒤져볼지도 모른다. O(n). 선형시간.

load factor. α = n/N (원소개수/테이블사이즈크기) -> 효율에 영향을 미친다.

어떤 key에 대해, 기대되는 probe 회수는 1/( 1- α)

ex) α = 50/100 이다.
그러면 기대되는 probe 횟수는 1/(1-1/2) 니까 2 이다. (평균프로브횟수)
-> 최악이아니라 평균적으로!
데이터 갯수에 비해 배열 크기가 커질수록 평균프로브횟수가 작아진다.

로드팩터 α 가 1에 가까워질수록 비효율적이 된다. 프로브를 많이하게된다.

딕셔너리 adt에서 해쉬테이블로 구현할경우 '평균수행시간'이 O(1)이다.

----------------------
한번 더하기로한거.
heap p.28
bottomup construction
크기가 31인 배열을 줬다 -> 크기가 31인 완전이진트리를 하나 줬다랑 같은말. 인덱스가 곧 노드가 되니까.

worst case를 만들어보자

예를들어 8번 16번 17번 노드가 있을때 8번노드가 down 되어야 worst가 된다. 이 때 오른쪽 으로 내려간다고 생각하고, 나머지도 (9-18-19, ....)도 다 똑같다고 하자.
그다음으로 4번, 8번, 9번. 4번이 말단까지가야 worst인데, 한번오른쪽 그이후로 다 왼쪽으로. 나머지 오른쪽 노드들도 마찬가지 수행.
그다음 2번, 4번, 5번. 2번이 말단까지가야되니까 한번 오른쪽 계속 왼쪽. 3번 6번 7번도.
마지막으로 1번, 2번, 3번까지 수행.
노드가 down힙 된 경로를 칠해보면, 그 경로가 하나도 겹치지 않고, 이 연산의 수를 세어볼 수 있다.

n개의 data가 있다 -> n개의 internal node -> n-1개의 edge노드(단말노드)가 있다.
이때 다운힙으로 내려온 노드들을 red edge라고 하면,
총 red edge <= n-1 이다.
노드 한개당 연산이 2번이므로,
총 비교연산은 2x(red edge수) = 2x(n-1)
따라서 총비교연산 <= 2(n-1) = O(n)이 된다.

bottom up heap construction의 최악수행시간은 O(n) -> heap sort의 1단계는 선형시간으로 구현할 수 있다.