2주차 -2

지난시간
베스트케이스, 에버리지케이스, 워스트케이스 가있는데
보통은 워스트케이스에 초점을 마춘다.

러닝타임을 n에 관한 함수로 표현한것이 이론분석
모든 경우에 대해.
하드웨어 소프트웨어 환경과 무관.

이론분석을 위한 이론적 컴퓨터, RAM, 앞으로할 알고리즘일이 실행되는
가상의 컴퓨터,
현실과 너무 동떨어지면 안되기에 우리가 사용하는 컴퓨터와 유사.

primitive operations : 상수시간에 수행되는 연산들, 함수들

p.10
이론분석을 수행하기위해 수도코드를 작성하고
가장 많이 수행될때, 각 라인에 수행되는 primitive operartions를 다세면
->input 크키 n에 관한 함수로 표현
저 6n-1가 이론분석

p.11
이 6n-1은 실제 수행되는 시간이아니라 그냥 p.o.의 개수이다.
가장 클락수가많을 때 b
가장 클락수가적을 때 a
a나 b는 상수
따라서 T(n)는 두 일차식 사이에 있으니,
즉 arrayMax라는 함수의 본질은 선형함수이다.
input크기가 n이면 그 n에 비례하는 함수이다.

-----------------------------------------------------------------

p. 12
함수의 증가율
우리가 하드웨어적 소프트웨어적 환경을 바꾸더라도
증가율은 바뀌지 않는다.
T(n)이 몇 상수배 이렇게 바뀔지라도. (by, constant factor)
즉, 예를들어
버블소트를 구현하는데
좋은 컴퓨터에서는 n 시간만큼 걸렸는데
나쁜 컴퓨터에서는 n에 제곱시간만큼 걸린다? --> X
뭐 몇 배 차이날수있지만(속도가달라지는거지), 그 증가율, 본질은 바뀌지 X
즉 T(n)은, 어느 컴퓨터에서 돌리던간에 '선형증가율'임은 바뀌지 않는다.
이건 arrayMax라는 함수의 본질적인 특성.

p.13
현실에선 kilo = 1000 (10^3)이지만
컴퓨터에선 kilo = 2^10
mega = 2^20 (약 10^6)
giga = 2^30 (약 10^9)

따라서, 앞으로 log1000은 log(2^10)으로 생각하자~ (밑은 2)
그래서 로그함수는
인풋이 1000일때 log(2^10)이니까 10
인풋이 2000일때 log(2^11)이니까 11
->로그함수에서는 인풋이 1000개가 들어났는데 연산은 1개가 늘어난다,,,!
증가율이 굉장히 더디다

제곱함수같은경우는 4배가 되고..

그냥 참고사항

p.14
insertion sort와 merge sort.
느린컴퓨터에서는 insertion는 70시간,
merge는 40초...
merge는 로그함수이지만 거의 선형함수와 같다. 눈으로 구분거의못한다.

p.15
Big-Oh 표기법

수행시간의 본질.
증가율을 나타낼 도구로써 사용할 Big-Oh 표기법.
원래 Big-Oh의 정의 : ppt화면

p.16
빅오 예시

우리는 항상 n0와 c를 찾아야하나?
아니다. 우리는 수학을 배우는게 아니라 그냥 도구기때문에.
어떤도구? 이론분석결과로 나온 함수의 본질만 표현하기 위한 도구.
그럼 어떻게?
예를들어 7n-2다 , 그러면 최고차항만 본다. 계수때버리고 나타내면 됨.
이것이 함수의 증가율이니까, 이거만 Big-oh 괄호안에 넣어두면된다.

p.17
빅오 표기법은 upper bound, 즉 어떤 함수 증가율의 "상한"이다.
원래 함수는 그 밑에 있다.
즉 증가율측면에서 작거나 같다. 넘어가지 않는다.
f(n) is O(g(n))이면 g(n)의 증가율이 더 빠르다는 뜻.
원래는 Big oh는 함수들의 집합이다.

P.18
big oh 룰

2n는 O(n)도되고 O(n^2)도 되지만
가장 저차항, 가장 타이트하게 사용한다
즉 O(n).
함수가 픽스되면 계수 다 떨구고, 저차항으로

p.19
asymptotic analysis : 점근분석
알고리즘에대한 수행시간을 n에관한 함수로 나타내고
big oh 를 씌어주면 그게 점근분석.

p.20
예제를 가지고 얘기해보자.
prefix average란
1월 의 평균수입.
1월+2월의 평균수입
1월 +2월+3월의 평균수입... 이 prefix average.

X[i]는 i월달의 입력.
A[i]는 것은 각 월별(0~i)매출액을 다 더해서 나눈 평균매출.

p.21
이 프리픽스에버리지를 구하는 알고리즘을 만들어보자.

p.22
아 알고리즘의 본질은 2차식이다. -> O(n^2)

p.23
근데 비효율적인 알고리즘이었다.
i번째까지 합을더해라면 0부터 i까지 더한다.
근데 i+1번까지 더하는게 또 0부터 i+1까지 더할필요없이
이전꺼에 i+1만 더하면 되지않나? -> 이거때문에 오래걸렸다.

prefixAverages2
sum을 그때그때 계산하는게 아니고
이전 결과를 활용한 알고리즘.
-> 1차식이 되었다.
알고리즘을 효율적으로 개선했더니
n제곱인거를 n으로 바꿨다, 아주 효율적으로 개선하였다.
(심지어 현실에서는 상수도 연구하는 분야가있는데..)

현실에서는 바로 효율적으로 만들기 쉽지않다.
일단은 그 문제를 해결하는 알고리즘을 만들어야한다.
따라서 우선 아웃풋을 만들어내는 알고리즘을 만드는게 먼저고,
성능개선은 나중이다.

p.24
Big oh와 비슷한 친구들.

big-omega는 하한(lower bound)을 나타낸다.
big-Theta 

p.25
빅오, 빅오메가, 빅세타 개념 알아두자.

p.26

+)질문
일반적으로 두개의 알고리즘의 big oh가 n^2으로 같다
-> 그러면 일반적으로 효율성은 같다고 본다.

하지만 average case에서는 다를 수 도 있다.
average case에서는 계수,상수를 보기도한다.
또 뒤에있는 저차항이 의외로 클수도 있고..

질문2.
알고리즘의 효율성을 분석할때 보통
최악수행시간을 기준으로 분석한다.